{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x136614230>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1383513d0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x174d3fd80>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1059c1ad0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x174ffa090>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x174d3fe60>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I  |  PRON  |  I  | \n",
      "ca  |  AUX  |  can  | \n",
      "n't  |  PART  |  not  | \n",
      "believe  |  VERB  |  believe  | \n",
      "some  |  DET  |  some  | \n",
      "cars  |  NOUN  |  car  | \n",
      "cost  |  VERB  |  cost  | \n",
      "over  |  ADP  |  over  | \n",
      "$  |  SYM  |  $  | \n",
      "15,000  |  NUM  |  15,000  | \n",
      "dollars  |  NOUN  |  dollar  | \n",
      "!  |  PUNCT  |  !  | \n"
     ]
    }
   ],
   "source": [
    "# Parts of Speech (POS) and Lemma Example \n",
    "\n",
    "doc = nlp(\"I can't believe some cars cost over $15,000 dollars!\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.pos_, \" | \", token.lemma_, \" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "$45 billion  |  MONEY  |  Monetary values, including unit\n",
      "US  |  GPE  |  Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition (NER) Example\n",
    "\n",
    "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion in the US\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to acquire twitter for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " in the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize with Displacy \n",
    "\n",
    "from spacy import displacy \n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Customizing Pipeline Compoenets\n",
    "\n",
    "nlp2 = spacy.blank(\"en\")  # Starts with nothing \n",
    "nlp2.add_pipe(\"ner\", source=nlp)\n",
    "nlp2.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raju  |  PROPN\n",
      "Paris  |  PROPN\n",
      "London  |  PROPN\n",
      "Dubai  |  PROPN\n",
      "Rome  |  PROPN\n",
      "Mohan  |  PROPN\n",
      "Hyderabad  |  PROPN\n",
      "Number of Proper Nouns Found:  7\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "\n",
    "# Get all the proper nouns from a given text in a list and also count how many of them.\n",
    "# Proper Noun means a noun that names a particular person, place, or thing.\n",
    "\n",
    "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and \n",
    "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
    "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
    "'''\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "doc2 = nlp(text)\n",
    "counter = 0\n",
    "for token in doc2:\n",
    "    if token.pos_ in [\"PROPN\"]:\n",
    "        counter += 1\n",
    "        print(token, \" | \", token.pos_)\n",
    "print(\"Number of Proper Nouns Found: \", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla ORG\n",
      "Walmart ORG\n",
      "Amazon ORG\n",
      "Microsoft ORG\n",
      "Google ORG\n",
      "Infosys ORG\n",
      "Reliance ORG\n",
      "HDFC Bank ORG\n",
      "Hindustan Unilever ORG\n",
      "Bharti ORG\n",
      "Number of Orgs Found: 10\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2 \n",
    "# Get all companies names from a given text and also the count of them.\n",
    "\n",
    "text2 = '''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in \n",
    "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel'''\n",
    "\n",
    "doc3 = nlp(text2)\n",
    "counter = 0 \n",
    "for ent in doc3.ents:\n",
    "    if ent.label_ == \"ORG\":\n",
    "        counter +=1\n",
    "        print(ent, ent.label_)\n",
    "print(\"Number of Orgs Found:\", counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
